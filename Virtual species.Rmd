```{r - virtual species}
library(sp)
library(raster)
library(SDMPlay)
library(spsurvey)
library(SOmap)
library(caret)

n_repeats = 2
full_n_pres_list = list()
full_kappa_v_list = list()
full_predictions_list = list()
full_sampling_sites_list = list()

for(i in 1:n_repeats){
  # Étape 1 : Préparation des données
  sample_size <- 200
  pres_sites <- sample_size/2
  abs_sites <- sample_size/2
  # Division en ensemble d'entraînement initial et ensemble de test
  pres_all = subset(HSMtable_KDE,HSMtable_KDE[,1] == 1)
  abs_all = subset(HSMtable_KDE,HSMtable_KDE[,1] == 0)
  pres <- pres_all[sample(nrow(pres_all), pres_sites), ]
  abs <- abs_all[sample(nrow(abs_all), abs_sites), ]
  training_data <- rbind(pres, abs)

  # Étape 2 : Modèle de base
  # Entraînement d'un modèle de base (p.ex. Random Forest)
  initial_model <- SDMPlay:::compute.brt(x = training_data, proj.predictors = stack_linear,
                                tc = 2, lr = 0.001, bf = 0.75, n.trees = 500, 
                                step.size = 500, n.folds = 5)
  initial_prediction = initial_model$raster.prediction
  # Calcul des quantiles pour définir les seuils
  threshold <- quantile(initial_prediction, probs = 0.9)
  # Classification binaire en utilisant les seuils
  binary_initial_prediction <- reclassify(initial_prediction, c(0,threshold, 0))
  binary_initial_prediction <- reclassify(binary_initial_prediction, c(threshold,1, 1))
  first_prediction = binary_initial_prediction
  
  basemap = SOmap(bathy_legend = F, ice = T, trim = -45, fronts = "Park", border = F) 
  plot(basemap)
  SOplot(first_prediction, col = hcl.colors(80, "viridis"), legend = F)
  
  predictions_list = list()
  predictions_list[[1]] = first_prediction
  sampling_sites_list = list()
  sampling_sites_list[[1]] = training_data
  
  # Étape 3 : Génération de l'espèce virtuelle
  setwd("/Users/charlieplasman/Desktop")
  virtual_species = raster("MYCTO_PRED.tif")
  # Classification binaire en utilisant les seuils
  binary_virtual_species <- reclassify(virtual_species, c(0,threshold, 0))
  binary_virtual_species <- reclassify(binary_virtual_species, c(threshold,1, 1))
  # Add the new raster to the existing stack
  envi_data = stack_linear
  envi_data <- addLayer(envi_data, binary_virtual_species)
  
  # Itérations
  iterations = 2
  new_presences_list <- list()
  kappa_values_list <- list()
    
  for(i in 1:iterations){
    # Étape 4 : Simulation de l'échantillonnage (GRTS)
    distrib_points <- rasterToPoints(binary_initial_prediction)
    distrib_points <- data.frame(distrib_points)
    # Visualiser la distribution des valeurs de profondeur
    hist(distrib_points$layer)
    
    sampling_effort = sample_size/2
    n_strata <- c("0" = sampling_effort , "1" = sampling_effort)
    
    # Convert the data frame 'distrib_points' to an 'sf' object
    distrib_points_sf <- st_as_sf(distrib_points, coords = c("x", "y"))
    print(st_crs(distrib_points_sf))
    # Définir le CRS géographique approprié (WGS84)
    geographic_crs <- st_crs("+proj=longlat +datum=WGS84 +no_defs")
    # Assigne le CRS géographique à ton objet
    st_crs(distrib_points_sf) <- geographic_crs
    # Vérifier que le CRS a été correctement défini
    print(st_crs(distrib_points_sf))
    # Définir le CRS projeté approprié (exemple : UTM)
    target_crs <- "+proj=utm +zone=30 +datum=WGS84 +units=m +no_defs"
    # Convertir les coordonnées géographiques en coordonnées projetées
    distrib_points_sf <- st_transform(distrib_points_sf, crs = target_crs)
    # Vérifier que le CRS a été correctement défini
    st_crs(distrib_points_sf)
  
    eqprob_strat <- grts(distrib_points_sf, n_base = n_strata, stratum_var = "layer")
    # Afficher les résultats
    print(eqprob_strat)
    plot(eqprob_strat, siteuse = "Base")
    
    sampling_sites = data.frame(latitude = eqprob_strat$sites_base$lat_WGS84, 
                                longitude = eqprob_strat$sites_base$lon_WGS84)
    sampling_sites = cbind.data.frame(sampling_sites$longitude,sampling_sites$latitude)
    colnames(sampling_sites) = c("longitude", "latitude")
    # Étape 5 : Ajout des nouvelles données
    sampled_sites_df = SDMPlay:::SDMtab(xydata=sampling_sites, predictors=envi_data, unique.data=F, same=F, background.nb = 0)
    count <- sum(sampled_sites_df$MYCTO_PRED == 1)
    new_presences_list[[i]] <- count
    # Supprimer la première colonne
    sampled_sites_df <- sampled_sites_df[, -1]
    # Placer la dernière colonne en première position
    last_column <- ncol(sampled_sites_df)
    sampled_sites_df <- sampled_sites_df[, c(last_column, 1:(last_column-1))]
    # Changer le nom de la première colonne (qui était la dernière)
    new_first_column_name <- "id"
    colnames(sampled_sites_df)[1] <- new_first_column_name
    sampling_sites_list = append(sampling_sites_list,list(sampled_sites_df))
    new_training_data = rbind(training_data,sampled_sites_df)
  
    # Étape 6 : Construction du modèle itératif
    iterative_model <- SDMPlay:::compute.brt(x = new_training_data, proj.predictors = stack_linear,
                                tc = 2, lr = 0.0001, bf = 0.75, n.trees = 500, 
                                step.size = 500, n.folds = 5)
    iterative_prediction = iterative_model$raster.prediction
    # Classification binaire en utilisant les seuils
    binary_iterative_prediction <- reclassify(iterative_prediction, c(0,threshold, 0))
    binary_iterative_prediction <- reclassify(binary_iterative_prediction, c(threshold,1, 1))
    plot(basemap)
    SOplot(binary_iterative_prediction, col = hcl.colors(80, "viridis"), legend = F)
    predictions_list = append(predictions_list,binary_iterative_prediction)
    # Réajuster les données d'entraînement pour la prochaine itération
    binary_initial_prediction = binary_iterative_prediction
    training_data = new_training_data
    
    # Étape 7 : Calcul des métriques
    # Load your binary raster predictions and known distribution raster
    prediction_raster <- binary_iterative_prediction
    known_distribution_raster <- binary_virtual_species
  
    prediction_matrix <- as.matrix(prediction_raster)
    known_distribution_matrix <- as.matrix(known_distribution_raster)
    prediction_vector <- as.vector(prediction_matrix)
    known_distribution_vector <- as.vector(known_distribution_matrix)
  
    # Convert vectors to factors with levels "0" and "1"
    prediction_factor <- factor(prediction_vector, levels = c("0", "1"))
    known_distribution_factor <- factor(known_distribution_vector, levels = c("0", "1"))
    confusion_matrix <- confusionMatrix(prediction_factor, known_distribution_factor)
  
    # Calculate Cohen's Kappa
    kappa_value <- confusion_matrix$overall['Kappa']
    # Display the Cohen's Kappa coefficient
    print(paste("Cohen's Kappa Coefficient:", kappa_value))
    kappa_values_list[[i]] = kappa_value
  }
  full_n_pres_list[[i]] = new_presences_list 
  full_kappa_v_list[[i]] = kappa_values_list
  full_predictions_list[[i]] = predictions_list
  full_sampling_sites_list[[i]] = sampling_sites_list
}
```

```{r - visualisation}
basemap = SOmap(bathy_legend = F, ice = T, trim = -45, fronts = "Park", border = F) 
plot(basemap)
SOplot(first_prediction, col = hcl.colors(80, "viridis"), legend = F)
plot(basemap)
SOplot(binary_iterative_prediction, col = hcl.colors(80, "viridis"), legend = F)
plot(basemap)
SOplot(binary_virtual_species, col = hcl.colors(80, "viridis"), legend = F)
```

```{r - random}
library(sp)
library(raster)
library(SDMPlay)
library(spsurvey)
library(SOmap)
library(caret)

n_repeats = 2
full_n_pres_list = list()
full_kappa_v_list = list()
full_predictions_list = list()
full_sampling_sites_list = list()

for(i in 1:n_repeats){
  # Étape 1 : Préparation des données
  sample_size <- 200
  pres_sites <- sample_size/2
  abs_sites <- sample_size/2
  # Division en ensemble d'entraînement initial et ensemble de test
  pres_all = subset(HSMtable_KDE,HSMtable_KDE[,1] == 1)
  abs_all = subset(HSMtable_KDE,HSMtable_KDE[,1] == 0)
  pres <- pres_all[sample(nrow(pres_all), pres_sites), ]
  abs <- abs_all[sample(nrow(abs_all), abs_sites), ]
  training_data <- rbind(pres, abs)

  # Étape 2 : Modèle de base
  # Entraînement d'un modèle de base (p.ex. Random Forest)
  initial_model <- SDMPlay:::compute.brt(x = training_data, proj.predictors = stack_linear,
                                tc = 2, lr = 0.001, bf = 0.75, n.trees = 500, 
                                step.size = 500, n.folds = 5)
  initial_prediction = initial_model$raster.prediction
  # Calcul des quantiles pour définir les seuils
  threshold <- quantile(initial_prediction, probs = 0.9)
  # Classification binaire en utilisant les seuils
  binary_initial_prediction <- reclassify(initial_prediction, c(0,threshold, 0))
  binary_initial_prediction <- reclassify(binary_initial_prediction, c(threshold,1, 1))
  first_prediction = binary_initial_prediction
  
  basemap = SOmap(bathy_legend = F, ice = T, trim = -45, fronts = "Park", border = F) 
  plot(basemap)
  SOplot(first_prediction, col = hcl.colors(80, "viridis"), legend = F)
  
  predictions_list = list()
  predictions_list[[1]] = first_prediction
  sampling_sites_list = list()
  sampling_sites_list[[1]] = training_data
  
  # Étape 3 : Génération de l'espèce virtuelle
  setwd("/Users/charlieplasman/Desktop")
  virtual_species = raster("MYCTO_PRED.tif")
  # Classification binaire en utilisant les seuils
  binary_virtual_species <- reclassify(virtual_species, c(0,threshold, 0))
  binary_virtual_species <- reclassify(binary_virtual_species, c(threshold,1, 1))
  # Add the new raster to the existing stack
  envi_data = stack_linear
  envi_data <- addLayer(envi_data, binary_virtual_species)
  
  # Itérations
  iterations = 2
  new_presences_list <- list()
  kappa_values_list <- list()
    
  for(i in 1:iterations){
    # Étape 4 : Simulation de l'échantillonnage 
    # Charger ta zone d'étude 
    study_area <- envi_data$gb_depth
    # Générer des points aléatoires dans la zone d'étude
    random_points <- spsample(study_area, n = sample_size, type = "random")
    random_points <- sampleRandom(study_area, size = sample_size, xy = TRUE)
    random_points=data.frame(random_points[,-3])
    # Afficher les premiers points générés
    head(random_points)
    sampling_sites = cbind.data.frame(random_points$x,random_points$y)
    colnames(sampling_sites) = c("longitude", "latitude")
    # Étape 5 : Ajout des nouvelles données
    sampled_sites_df = SDMPlay:::SDMtab(xydata=sampling_sites, predictors=envi_data, unique.data=F, same=F, background.nb = 0)
    count <- sum(sampled_sites_df$MYCTO_PRED == 1)
    new_presences_list[[i]] <- count
    # Supprimer la première colonne
    sampled_sites_df <- sampled_sites_df[, -1]
    # Placer la dernière colonne en première position
    last_column <- ncol(sampled_sites_df)
    sampled_sites_df <- sampled_sites_df[, c(last_column, 1:(last_column-1))]
    # Changer le nom de la première colonne (qui était la dernière)
    new_first_column_name <- "id"
    colnames(sampled_sites_df)[1] <- new_first_column_name
    sampling_sites_list = append(sampling_sites_list,list(sampled_sites_df))
    new_training_data = rbind(training_data,sampled_sites_df)
  
    # Étape 6 : Construction du modèle itératif
    iterative_model <- SDMPlay:::compute.brt(x = new_training_data, proj.predictors = stack_linear,
                                tc = 2, lr = 0.0001, bf = 0.75, n.trees = 500, 
                                step.size = 500, n.folds = 5)
    iterative_prediction = iterative_model$raster.prediction
    # Classification binaire en utilisant les seuils
    binary_iterative_prediction <- reclassify(iterative_prediction, c(0,threshold, 0))
    binary_iterative_prediction <- reclassify(binary_iterative_prediction, c(threshold,1, 1))
    plot(basemap)
    SOplot(binary_iterative_prediction, col = hcl.colors(80, "viridis"), legend = F)
    predictions_list = append(predictions_list,binary_iterative_prediction)
    # Réajuster les données d'entraînement pour la prochaine itération
    binary_initial_prediction = binary_iterative_prediction
    training_data = new_training_data
    
    # Étape 7 : Calcul des métriques
    # Load your binary raster predictions and known distribution raster
    prediction_raster <- predictions_list[[i+1]]
    known_distribution_raster <- binary_virtual_species
  
    prediction_matrix <- as.matrix(prediction_raster)
    known_distribution_matrix <- as.matrix(known_distribution_raster)
    prediction_vector <- as.vector(prediction_matrix)
    known_distribution_vector <- as.vector(known_distribution_matrix)
  
    # Convert vectors to factors with levels "0" and "1"
    prediction_factor <- factor(prediction_vector, levels = c("0", "1"))
    known_distribution_factor <- factor(known_distribution_vector, levels = c("0", "1"))
    confusion_matrix <- confusionMatrix(prediction_factor, known_distribution_factor)
  
    # Calculate Cohen's Kappa
    kappa_value <- confusion_matrix$overall['Kappa']
    # Display the Cohen's Kappa coefficient
    print(paste("Cohen's Kappa Coefficient:", kappa_value))
    kappa_values_list[[i]] = kappa_value
  }
  full_n_pres_list[[i]] = new_presences_list 
  full_kappa_v_list[[i]] = kappa_values_list
  full_predictions_list[[i]] = predictions_list
  full_sampling_sites_list[[i]] = sampling_sites_list
}
```

```{r}
setwd("/Users/charlieplasman/Desktop")
mycto = raster("MYCTO_PRED.tif")
suitability = 
ecosimi = 
extra =
sampling = 
)
```

